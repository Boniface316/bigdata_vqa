{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from bigdatavqa.coreset import normalize_np\n",
    "from bigdatavqa.datautils import DataUtils\n",
    "from bigdatavqa.k3meansclustering import get_coreset_vec_and_weights\n",
    "from bigdatavqa.coreset import coreset_to_graph\n",
    "from bigdatavqa.k3meansclustering import get_3means_clusters_centers, get_3means_cost\n",
    "from bigdatavqa.postexecution import get_k_means_accumulative_cost\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cost = np.inf\n",
    "\n",
    "qubits = 10\n",
    "coreset_size = int(qubits / 2)\n",
    "circuit_depth = 1\n",
    "max_shots = 1000\n",
    "max_iterations = 100 \n",
    "number_of_experiment_runs = 5\n",
    "data_location = \"../data\"\n",
    "number_of_corsets_to_evaluate = 15\n",
    "number_of_centroid_evaluation = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create coreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from ../data/dataset.pickle\n"
     ]
    }
   ],
   "source": [
    "data_utils = DataUtils(data_location)\n",
    "raw_data = data_utils.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreset_vectors, coreset_weights = get_coreset_vec_and_weights(\n",
    "    raw_data,\n",
    "    coreset_size,\n",
    "    number_of_corsets_to_evaluate,\n",
    "    number_of_centroid_evaluation,\n",
    ")\n",
    "\n",
    "\n",
    "coreset_vectors_for_graph = normalize_np(coreset_vectors, centralize=True)\n",
    "coreset_weights_for_graph = normalize_np(coreset_weights, centralize=False)\n",
    "\n",
    "coreset_graph, _ = coreset_to_graph(\n",
    "    coreset_vectors_for_graph,\n",
    "    coreset_weights_for_graph,\n",
    "    number_of_qubits_representing_data=2,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "NLOpt runtime error: nlopt failure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_experiment_runs):\n\u001b[0;32m----> 2\u001b[0m     cluster_centers \u001b[38;5;241m=\u001b[39m \u001b[43mget_3means_clusters_centers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoreset_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoreset_vectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoreset_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcircuit_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_shots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     cost \u001b[38;5;241m=\u001b[39m get_3means_cost(raw_data, cluster_centers)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cost \u001b[38;5;241m<\u001b[39m best_cost:\n",
      "File \u001b[0;32m~/Projects/experiments/VQA/src/bigdatavqa/k3meansclustering/_3meansclustering.py:88\u001b[0m, in \u001b[0;36mget_3means_clusters_centers\u001b[0;34m(coreset_graph, coreset_vectors, coreset_weights, circuit_depth, max_shots, max_iterations)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_3means_clusters_centers\u001b[39m(\n\u001b[1;32m     80\u001b[0m     coreset_graph,\n\u001b[1;32m     81\u001b[0m     coreset_vectors,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m ):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# prviusly approx_clusters\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     partition \u001b[38;5;241m=\u001b[39m \u001b[43mget_approximate_partition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoreset_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuit_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_shots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iterations\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [[0], [4, 8], [2, 6]]\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     cluster_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(coreset_vectors[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     94\u001b[0m     clusters_centers \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mzeros(cluster_size)] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/experiments/VQA/src/bigdatavqa/k3meansclustering/_3meansclustering.py:134\u001b[0m, in \u001b[0;36mget_approximate_partition\u001b[0;34m(coreset_graph, circuit_depth, max_shots, max_iterations)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03mFinds approximate partition of the data\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Simulate VQE to find the aprroximate state\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mapprox_optimal_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoreset_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuit_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_shots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iterations\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Initialise the sets\u001b[39;00m\n\u001b[1;32m    138\u001b[0m s1, s2, s3, sets \u001b[38;5;241m=\u001b[39m [], [], [], []\n",
      "File \u001b[0;32m~/Projects/experiments/VQA/src/bigdatavqa/k3meansclustering/_3meansclustering.py:184\u001b[0m, in \u001b[0;36mapprox_optimal_state\u001b[0;34m(coreset_graph, circuit_depth, max_iterations, max_shots)\u001b[0m\n\u001b[1;32m    178\u001b[0m optimizer, parameter_count \u001b[38;5;241m=\u001b[39m get_optimizer(\n\u001b[1;32m    179\u001b[0m     max_iterations, circuit_depth, number_of_qubits\n\u001b[1;32m    180\u001b[0m )\n\u001b[1;32m    182\u001b[0m Hamiltonian \u001b[38;5;241m=\u001b[39m get_3means_Hamiltonian(coreset_graph)\n\u001b[0;32m--> 184\u001b[0m _, optimal_parameters \u001b[38;5;241m=\u001b[39m \u001b[43mcudaq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvqe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_two_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber_of_qubits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuit_depth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspin_operator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHamiltonian\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameter_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_shots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m counts \u001b[38;5;241m=\u001b[39m cudaq\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    193\u001b[0m     kernel_two_local(number_of_qubits, circuit_depth),\n\u001b[1;32m    194\u001b[0m     optimal_parameters,\n\u001b[1;32m    195\u001b[0m     shots_count\u001b[38;5;241m=\u001b[39mmax_shots,\n\u001b[1;32m    196\u001b[0m )\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Find the state that was measured most frequently\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# opt_state return from the original code - i.e 0011100110\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NLOpt runtime error: nlopt failure"
     ]
    }
   ],
   "source": [
    "for _ in range(number_of_experiment_runs):\n",
    "    cluster_centers = get_3means_clusters_centers(\n",
    "        coreset_graph,\n",
    "        coreset_vectors,\n",
    "        coreset_weights,\n",
    "        circuit_depth,\n",
    "        max_shots,\n",
    "        max_iterations,\n",
    "    )\n",
    "\n",
    "    cost = get_3means_cost(raw_data, cluster_centers)\n",
    "    if cost < best_cost:\n",
    "        best_cost = cost\n",
    "        best_cluster_centers = cluster_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreset_vectors = pd.DataFrame.to_numpy(coreset_df[['X', 'Y']])\n",
    "weight_vectors = pd.Series.to_numpy(coreset_df['weights'])\n",
    "cluster_vectors = pd.DataFrame.to_numpy(cluster_df)\n",
    "\n",
    "non_weighted_cost = get_k_means_accumulative_cost(3, cluster_vectors, coreset_vectors)\n",
    "weighted_cost = get_k_means_accumulative_cost(3, cluster_vectors, coreset_vectors, weight_vectors)\n",
    "\n",
    "VQE_cost_value = weighted_cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VQA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
