{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb86f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from divisiveclustering.datautils import DataUtils\n",
    "from divisiveclustering.coresetsUtils import Coreset, normalize_np ,gen_coreset_graph\n",
    "from divisiveclustering.vqe_utils import kernel_two_local, create_Hamiltonian_for_K2, get_Hamil_variables\n",
    "from divisiveclustering.quantumutils import get_probs_table\n",
    "import cudaq\n",
    "import numpy as np\n",
    "import warnings\n",
    "from divisiveclustering.coresetsUtils import gen_coreset_graph\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from divisiveclustering.helpers import add_children_to_hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a58cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_qubits = 5\n",
    "layer_count = 1\n",
    "parameter_count = 4 * layer_count * (number_of_qubits - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43397c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from ../../data/dataset.pickle\n"
     ]
    }
   ],
   "source": [
    "data_utils = DataUtils('../../data')\n",
    "\n",
    "try:\n",
    "    raw_data = data_utils.load_dataset()\n",
    "except:\n",
    "    raw_data = data_utils.create_dataset(n_samples = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51aa013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coreset_vectors = data_utils.load_dataset(\"5_coreset_vectors.npy\")\n",
    "coreset_weights = data_utils.load_dataset(\"5_coreset_weights.npy\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc0046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coreset_points, G, H, weight_matrix, weights = gen_coreset_graph(\n",
    "    coreset_vectors, coreset_weights, metric=\"dot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af22418",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamiltonian = create_Hamiltonian_for_K2(G, number_of_qubits, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40605b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qubits = number_of_qubits\n",
    "max_iterations = 100\n",
    "max_shots = 10\n",
    "parameter_count = 4 * layer_count * (qubits - 1)\n",
    "\n",
    "optimizer = cudaq.optimizers.COBYLA()\n",
    "optimizer.initial_parameters = np.random.uniform(-np.pi / 8.0, np.pi / 8.0,\n",
    "                                         parameter_count)\n",
    "optimizer.max_iterations = max_iterations\n",
    "\n",
    "optimal_expectation, optimal_parameters = cudaq.vqe(\n",
    "    kernel=kernel_two_local(qubits, layer_count),\n",
    "    spin_operator=hamiltonian,\n",
    "    optimizer=optimizer,\n",
    "    parameter_count=parameter_count,\n",
    "    shots = max_shots)\n",
    "\n",
    "counts = cudaq.sample(kernel_two_local(qubits, layer_count), optimal_parameters, shots_count = max_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c60fb91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 11001:9 00110:1 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
